# **Behavioral Cloning** 

## Writeup- Behavioral Cloning Project

The goals / steps of this project are the following:
* Use the simulator to collect data of good driving behavior
* Build, a convolution neural network in Keras that predicts steering angles from images
* Train and validate the model with a training and validation set
* Test that the model successfully drives around track one without leaving the road
* Summarize the results with a written report


[//]: # (Image References)

[image1]: ./writeupImages/architectureSummary.PNG "Model Visualization"
[image2]: ./writeupImages/center_2018_02_26_20_55_35_140.jpg "Recovery"
[image3]: ./writeupImages/center_2018_02_26_21_08_58_074.jpg "Recovery Image"
[image4]: ./writeupImages/flipped.jpg "flipped Image"
[image5]: ./writeupImages/nvidiaArch.png "nvidiaArch Image"
[image6]: ./writeupImages/original.jpg "orig Image"
[image7]: ./writeupImages/right_2018_02_26_20_56_15_487.jpg "recovery Image"
[image8]: ./writeupImages/right_2018_02_26_21_08_58_644.jpg "recovery Image"

### Files Submitted & Code Quality

#### 1. Submission includes all required files and can be used to run the simulator in autonomous mode

My project includes the following files:
* model.py containing the script to create and train the model
* drive.py for driving the car in autonomous mode
* model.h5 containing a trained convolution neural network 
* writeup_report.md or writeup_report.pdf summarizing the results

#### 2. Submission includes functional code
Using the Udacity provided simulator and my drive.py file, the car can be driven autonomously around the track by executing 
```sh
python drive.py model.h5
```

#### 3. Submission code is usable and readable

The model.py file contains the code for training and saving the convolution neural network. The file shows the pipeline I used for training and validating the model, and it contains comments to explain how the code works.

### Model Architecture and Training Strategy

#### 1. An appropriate model architecture has been employed

My model consists of a convolution neural network with 3x3 and 5X5 filter sizes and depths between 24 and 64. 
The model includes ELU layers to introduce nonlinearity, and the data is normalized in the model using a Keras lambda layer **Lambda(lambda x: (x/127.5)-1)**. I have used 5 convolution layers and 4 fully connected layers along with flatten and drop out.

#### 2. Attempts to reduce overfitting in the model

The model contains a dropout layer(prob=0.25) in order to reduce overfitting. 
The model was trained and validated on different data sets(I split the data by factor of 1.5) to ensure that the model was not overfitting.
Also I flipped the images in the test data so that there is no bias for the left curve, which was more prominent in the first track.
The model was tested by running it through the simulator and ensuring that the vehicle could stay on the track.

#### 3. Model parameter tuning

* The model used an adam optimizer, so the learning rate was not tuned manually.
* I kept the batch size 64
* correction factor= 0.2 for adjust left and right camera images
* and ran the model for 5 epochs

#### 4. Appropriate training data

Training data was chosen to keep the vehicle driving on the road. I used a combination of center lane driving, recovering from the left and right sides of the road to train the model to stay in the center. 
I used as much data as possible for training the model better. There were 120,000+ images to train the model acquired from simulator for both the tracks and all three cameras.
I also used the Udacity sample data as well as data generated by my colleagues.

### Model Architecture and Training Strategy

#### 1. Solution Design Approach

The overall strategy for deriving a model architecture was to keep the model performance effective. Since the dataset was large and response time in real life scenario is less. model should be efficient enough to crunch numbers as quickly as possible.

My first step was to use a convolution neural network model similar to the NVIDIA model... I thought this model might be appropriate because it is a well known model for autonomous car driving and image processing. ***But I did not use exactly the same model. I removed some layers and adjusted the dimensions.***

![alt text][image5]

**NVIDIA Architecture** source: devblogs.nvidia.com

In order to gauge how well the model was working, I split my image and steering angle data into a training and validation set. I found that my first model had a low mean squared error on the training set but a high mean squared error on the validation set. This implied that the model was overfitting. 

To combat the overfitting, I added drop outs after each layer but that didn't work well with the simulator result. So after multiple rounds of experimentation I settled for just one drop out after flatten layer with a prob of 0.25

There were a few spots where the vehicle fell off the track especially at the turns after the bridge in track 1 and the first turn in track 2. To improve the driving behavior in these cases, after various model changes I decided to go for more training data.

At the end of the process, the vehicle is able to drive autonomously around the track without leaving the road.

#### 2. Final Model Architecture

**Here is the summary of the architecture I am using**

![alt text][image1]

#### 3. Creation of the Training Set & Training Process
Training data for second track was harder to accumulate 
To capture good driving behavior, I first recorded two laps on track one using center lane driving. I also drove recovery strides from the left road edge and right road edge inwards of the road to train teh model to follow that when near the raod edge.

**Recovery Images**

![alt text][image3]
![alt text][image2]
![alt text][image7]
![alt text][image8]

After the collection process, I had approx 22,000+ lines of data(3 images per line from each camera) accumulated in the CSV file.
I shuffled these data lines and created separate sets for validation and training.

I then Augmented this data by flipping it so that the model has enough data to follow the same for both sides of the road and this increased the images to 120,000+. This augmentation was done in a generator function. 

**Flipped Images**

![alt text][image6]
![alt text][image4]

Generator helps to feed the data into the model in batches. Resource intensive tasks require generator to create and feed the data to the model on demand. This keeps the memory available for training, otherwise the dataset being large, exhausts all the primary memory of the system and sometimes even if Cloud GPUS are used. Free tier access to these GPUs have resource limits and if this is exhausted even the GPU cannot process the images. 

So it's a good practice to not load the whole dataset into the memory at once and process it on the fly.


Then I repeated this process on track two in order to get more data points.
I finally merged both the datasets and trained the model using the generator to do load and augmentation. A batch of 64 lines had 3 images per line. After flipping each of these images, 64X3X2 images were generated per batch and this batch was called many times during an epoch.

To be more precise, ~22000/64 times.

Since Adam optimizer was used to learning rate is not defined and I decided to go with the default learning rate.

#### 4. Preprocessing

I normalized the input images and adjusted the left and right camera angle values. Also I cropped the images from top and bottom to remove the unnecessary parts of the image.

### Problems faced during the project

1. Simulator's RAM consumption is high and slows down the system, as well as the simulator making it difficult to generate training data
2. Model performance while autonomous drive various according to the performance of the simulator, this makes it difficult to test the model.

### Summary

My personal experience with the project showed that the performance of the car on road was more dependent on the training data rather than the model. I kept facing problems until I decided to increase my training data. I also saw some architectures that used only 3-4 layers and worked fine and robust. However I stuck to the model I designed and tested and it was enough to keep my car from falling off the road.


